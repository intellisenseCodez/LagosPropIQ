{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eb05a-23c7-46dc-be9a-2114488c12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction from land.ng website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ea75d7-7e18-4b8d-a394-e9d7d9af0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import necessary libaries \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b53fb-c0f6-43b2-a402-69344178bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load the wesite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aba6222-b79e-4b16-be13-e0daddf0f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 500\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://land.ng/search-results/?keyword=&states%5B%5D=lagos\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/126.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(URL, headers=headers, timeout=15)\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685cd680-e3e5-49aa-b982-2c0746618b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
       "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
       "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
       "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
       "<head>\n",
       "<title>land.ng | 500: Internal server error</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"noindex, nofollow\" name=\"robots\"/>\n",
       "<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\n",
       "<link href=\"/cdn-cgi/styles/main.css\" id=\"cf_styles-css\" rel=\"stylesheet\"/>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"cf-wrapper\">\n",
       "<div class=\"p-0\" id=\"cf-error-details\">\n",
       "<header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
       "<h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
       "<span class=\"inline-block\">Internal server error</span>\n",
       "<span class=\"code-label\">Error code 500</span>\n",
       "</h1>\n",
       "<div>\n",
       "                Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_500&amp;utm_campaign=land.ng\" rel=\"noopener noreferrer\" target=\"_blank\">cloudflare.com</a> for more information.\n",
       "            </div>\n",
       "<div class=\"mt-3\">2025-11-18 14:15:25 UTC</div>\n",
       "</header>\n",
       "<div class=\"my-8 bg-gradient-gray\">\n",
       "<div class=\"w-240 lg:w-full mx-auto\">\n",
       "<div class=\"clearfix md:px-8\">\n",
       "<div class=\"relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\" id=\"cf-browser-status\">\n",
       "<div class=\"relative mb-10 md:m-0\">\n",
       "<span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
       "<span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
       "</div>\n",
       "<span class=\"md:block w-full truncate\">You</span>\n",
       "<h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
       "  \n",
       "    Browser\n",
       "  \n",
       "  </h3>\n",
       "<span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
       "</div>\n",
       "<div class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\" id=\"cf-cloudflare-status\">\n",
       "<div class=\"relative mb-10 md:m-0\">\n",
       "<a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_500&amp;utm_campaign=land.ng\" rel=\"noopener noreferrer\" target=\"_blank\">\n",
       "<span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
       "<span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
       "</a>\n",
       "</div>\n",
       "<span class=\"md:block w-full truncate\">London</span>\n",
       "<h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
       "<a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_500&amp;utm_campaign=land.ng\" rel=\"noopener noreferrer\" target=\"_blank\">\n",
       "    Cloudflare\n",
       "  </a>\n",
       "</h3>\n",
       "<span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
       "</div>\n",
       "<div class=\"relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\" id=\"cf-host-status\">\n",
       "<div class=\"relative mb-10 md:m-0\">\n",
       "<span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
       "<span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
       "</div>\n",
       "<span class=\"md:block w-full truncate\">land.ng</span>\n",
       "<h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
       "  \n",
       "    Host\n",
       "  \n",
       "  </h3>\n",
       "<span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
       "<div class=\"clearfix\">\n",
       "<div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
       "<h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
       "<p>There is an internal server error on Cloudflare's network.</p>\n",
       "</div>\n",
       "<div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
       "<h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
       "<p class=\"mb-6\">Please try again in a few minutes.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
       "<p class=\"text-13\">\n",
       "<span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">9a0814714b8def59</strong></span>\n",
       "<span class=\"cf-footer-separator sm:hidden\">â€¢</span>\n",
       "<span class=\"cf-footer-item hidden sm:block sm:mb-1\" id=\"cf-footer-item-ip\">\n",
       "        Your IP:\n",
       "        <button class=\"cf-footer-ip-reveal-btn\" id=\"cf-footer-ip-reveal\" type=\"button\">Click to reveal</button>\n",
       "<span class=\"hidden\" id=\"cf-footer-ip\">102.90.82.92</span>\n",
       "<span class=\"cf-footer-separator sm:hidden\">â€¢</span>\n",
       "</span>\n",
       "<span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_500&amp;utm_campaign=land.ng\" id=\"brand_link\" rel=\"noopener noreferrer\" target=\"_blank\">Cloudflare</a></span>\n",
       "</p>\n",
       "<script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
       "</div><!-- /.error-footer -->\n",
       "</div>\n",
       "</div>\n",
       "<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'9a0814714b8def59',t:'MTc2MzQ3NTMyNQ=='};var a=document.createElement('script');a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><script crossorigin=\"anonymous\" data-cf-beacon='{\"version\":\"2024.11.0\",\"token\":\"3173afe5e83e4d1f9a6a95a60776d193\",\"r\":1,\"server_timing\":{\"name\":{\"cfCacheStatus\":true,\"cfEdge\":true,\"cfExtPri\":true,\"cfL4\":true,\"cfOrigin\":true,\"cfSpeedBrain\":true},\"location_startswith\":null}}' defer=\"\" integrity=\"sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==\" src=\"https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015\"></script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c02db668-3da5-47c0-85de-f6b5e1fbf64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Scraping page 1 ...\n",
      "ðŸ”Ž Scraping page 2 ...\n",
      "ðŸ”Ž Scraping page 3 ...\n",
      "ðŸ”Ž Scraping page 4 ...\n",
      "ðŸ”Ž Scraping page 5 ...\n",
      "ðŸ”Ž Scraping page 6 ...\n",
      "ðŸ”Ž Scraping page 7 ...\n",
      "ðŸ”Ž Scraping page 8 ...\n",
      "ðŸ”Ž Scraping page 9 ...\n",
      "ðŸ”Ž Scraping page 10 ...\n",
      "ðŸ”Ž Scraping page 11 ...\n",
      "ðŸ”Ž Scraping page 12 ...\n",
      "ðŸ”Ž Scraping page 13 ...\n",
      "ðŸ”Ž Scraping page 14 ...\n",
      "ðŸ”Ž Scraping page 15 ...\n",
      "ðŸ”Ž Scraping page 16 ...\n",
      "ðŸ”Ž Scraping page 17 ...\n",
      "ðŸ”Ž Scraping page 18 ...\n",
      "ðŸ”Ž Scraping page 19 ...\n",
      "ðŸ”Ž Scraping page 20 ...\n",
      "ðŸ”Ž Scraping page 21 ...\n",
      "ðŸ”Ž Scraping page 22 ...\n",
      "ðŸ”Ž Scraping page 23 ...\n",
      "ðŸ”Ž Scraping page 24 ...\n",
      "ðŸ”Ž Scraping page 25 ...\n",
      "ðŸ”Ž Scraping page 26 ...\n",
      "ðŸ”Ž Scraping page 27 ...\n",
      "ðŸ”Ž Scraping page 28 ...\n",
      "ðŸ”Ž Scraping page 29 ...\n",
      "ðŸ”Ž Scraping page 30 ...\n",
      "ðŸ”Ž Scraping page 31 ...\n",
      "ðŸ”Ž Scraping page 32 ...\n",
      "ðŸ”Ž Scraping page 33 ...\n",
      "ðŸ”Ž Scraping page 34 ...\n",
      "ðŸ”Ž Scraping page 35 ...\n",
      "ðŸ”Ž Scraping page 36 ...\n",
      "ðŸ”Ž Scraping page 37 ...\n",
      "ðŸ”Ž Scraping page 38 ...\n",
      "ðŸ”Ž Scraping page 39 ...\n",
      "ðŸ”Ž Scraping page 40 ...\n",
      "ðŸ”Ž Scraping page 41 ...\n",
      "ðŸ”Ž Scraping page 42 ...\n",
      "ðŸ”Ž Scraping page 43 ...\n",
      "ðŸ”Ž Scraping page 44 ...\n",
      "ðŸ”Ž Scraping page 45 ...\n",
      "ðŸ”Ž Scraping page 46 ...\n",
      "ðŸ”Ž Scraping page 47 ...\n",
      "ðŸ”Ž Scraping page 48 ...\n",
      "ðŸ”Ž Scraping page 49 ...\n",
      "ðŸ”Ž Scraping page 50 ...\n",
      "ðŸ”Ž Scraping page 51 ...\n",
      "ðŸ”Ž Scraping page 52 ...\n",
      "ðŸ”Ž Scraping page 53 ...\n",
      "ðŸ”Ž Scraping page 54 ...\n",
      "ðŸ”Ž Scraping page 55 ...\n",
      "ðŸ”Ž Scraping page 56 ...\n",
      "ðŸ”Ž Scraping page 57 ...\n",
      "ðŸ”Ž Scraping page 58 ...\n",
      "ðŸ”Ž Scraping page 59 ...\n",
      "ðŸ”Ž Scraping page 60 ...\n",
      "ðŸ”Ž Scraping page 61 ...\n",
      "ðŸ”Ž Scraping page 62 ...\n",
      "ðŸ”Ž Scraping page 63 ...\n",
      "ðŸ”Ž Scraping page 64 ...\n",
      "ðŸ”Ž Scraping page 65 ...\n",
      "ðŸ”Ž Scraping page 66 ...\n",
      "ðŸ”Ž Scraping page 67 ...\n",
      "ðŸ”Ž Scraping page 68 ...\n",
      "ðŸ”Ž Scraping page 69 ...\n",
      "ðŸ”Ž Scraping page 70 ...\n",
      "ðŸ”Ž Scraping page 71 ...\n",
      "ðŸ”Ž Scraping page 72 ...\n",
      "ðŸ”Ž Scraping page 73 ...\n",
      "ðŸ”Ž Scraping page 74 ...\n",
      "ðŸ”Ž Scraping page 75 ...\n",
      "ðŸ”Ž Scraping page 76 ...\n",
      "ðŸ”Ž Scraping page 77 ...\n",
      "ðŸ”Ž Scraping page 78 ...\n",
      "ðŸ”Ž Scraping page 79 ...\n",
      "ðŸ”Ž Scraping page 80 ...\n",
      "ðŸ”Ž Scraping page 81 ...\n",
      "ðŸ”Ž Scraping page 82 ...\n",
      "ðŸ”Ž Scraping page 83 ...\n",
      "ðŸ”Ž Scraping page 84 ...\n",
      "ðŸ”Ž Scraping page 85 ...\n",
      "ðŸ”Ž Scraping page 86 ...\n",
      "ðŸ”Ž Scraping page 87 ...\n",
      "ðŸ”Ž Scraping page 88 ...\n",
      "ðŸ”Ž Scraping page 89 ...\n",
      "ðŸ”Ž Scraping page 90 ...\n",
      "ðŸ”Ž Scraping page 91 ...\n",
      "ðŸ”Ž Scraping page 92 ...\n",
      "ðŸ”Ž Scraping page 93 ...\n",
      "ðŸ”Ž Scraping page 94 ...\n",
      "ðŸ”Ž Scraping page 95 ...\n",
      "ðŸ”Ž Scraping page 96 ...\n",
      "ðŸ”Ž Scraping page 97 ...\n",
      "ðŸ”Ž Scraping page 98 ...\n",
      "ðŸ”Ž Scraping page 99 ...\n",
      "ðŸ”Ž Scraping page 100 ...\n",
      "ðŸ”Ž Scraping page 101 ...\n",
      "ðŸ”Ž Scraping page 102 ...\n",
      "ðŸ”Ž Scraping page 103 ...\n",
      "ðŸ”Ž Scraping page 104 ...\n",
      "ðŸ”Ž Scraping page 105 ...\n",
      "ðŸ”Ž Scraping page 106 ...\n",
      "ðŸ”Ž Scraping page 107 ...\n",
      "ðŸ”Ž Scraping page 108 ...\n",
      "ðŸ”Ž Scraping page 109 ...\n",
      "ðŸ”Ž Scraping page 110 ...\n",
      "ðŸ”Ž Scraping page 111 ...\n",
      "ðŸ”Ž Scraping page 112 ...\n",
      "ðŸ”Ž Scraping page 113 ...\n",
      "ðŸ”Ž Scraping page 114 ...\n",
      "ðŸ”Ž Scraping page 115 ...\n",
      "ðŸ”Ž Scraping page 116 ...\n",
      "ðŸ”Ž Scraping page 117 ...\n",
      "ðŸ”Ž Scraping page 118 ...\n",
      "ðŸ”Ž Scraping page 119 ...\n",
      "ðŸ”Ž Scraping page 120 ...\n",
      "ðŸ”Ž Scraping page 121 ...\n",
      "ðŸ”Ž Scraping page 122 ...\n",
      "ðŸ”Ž Scraping page 123 ...\n",
      "ðŸ”Ž Scraping page 124 ...\n",
      "ðŸ”Ž Scraping page 125 ...\n",
      "ðŸ”Ž Scraping page 126 ...\n",
      "ðŸ”Ž Scraping page 127 ...\n",
      "ðŸ”Ž Scraping page 128 ...\n",
      "ðŸ”Ž Scraping page 129 ...\n",
      "ðŸ”Ž Scraping page 130 ...\n",
      "ðŸ”Ž Scraping page 131 ...\n",
      "ðŸ”Ž Scraping page 132 ...\n",
      "ðŸ”Ž Scraping page 133 ...\n",
      "ðŸ”Ž Scraping page 134 ...\n",
      "ðŸ”Ž Scraping page 135 ...\n",
      "ðŸ”Ž Scraping page 136 ...\n",
      "ðŸ”Ž Scraping page 137 ...\n",
      "ðŸ”Ž Scraping page 138 ...\n",
      "ðŸ”Ž Scraping page 139 ...\n",
      "ðŸ”Ž Scraping page 140 ...\n",
      "ðŸ”Ž Scraping page 141 ...\n",
      "ðŸ”Ž Scraping page 142 ...\n",
      "ðŸ”Ž Scraping page 143 ...\n",
      "ðŸ”Ž Scraping page 144 ...\n",
      "ðŸ”Ž Scraping page 145 ...\n",
      "ðŸ”Ž Scraping page 146 ...\n",
      "ðŸ”Ž Scraping page 147 ...\n",
      "ðŸ”Ž Scraping page 148 ...\n",
      "ðŸ”Ž Scraping page 149 ...\n",
      "ðŸ”Ž Scraping page 150 ...\n",
      "ðŸ”Ž Scraping page 151 ...\n",
      "ðŸ”Ž Scraping page 152 ...\n",
      "ðŸ”Ž Scraping page 153 ...\n",
      "ðŸ”Ž Scraping page 154 ...\n",
      "ðŸ”Ž Scraping page 155 ...\n",
      "ðŸ”Ž Scraping page 156 ...\n",
      "ðŸ”Ž Scraping page 157 ...\n",
      "ðŸ”Ž Scraping page 158 ...\n",
      "ðŸ”Ž Scraping page 159 ...\n",
      "ðŸ”Ž Scraping page 160 ...\n",
      "ðŸ”Ž Scraping page 161 ...\n",
      "ðŸ”Ž Scraping page 162 ...\n",
      "ðŸ”Ž Scraping page 163 ...\n",
      "ðŸ”Ž Scraping page 164 ...\n",
      "ðŸ”Ž Scraping page 165 ...\n",
      "ðŸ”Ž Scraping page 166 ...\n",
      "ðŸ”Ž Scraping page 167 ...\n",
      "ðŸ”Ž Scraping page 168 ...\n",
      "ðŸ”Ž Scraping page 169 ...\n",
      "ðŸ”Ž Scraping page 170 ...\n",
      "ðŸ”Ž Scraping page 171 ...\n",
      "ðŸ”Ž Scraping page 172 ...\n",
      "ðŸ”Ž Scraping page 173 ...\n",
      "ðŸ”Ž Scraping page 174 ...\n",
      "ðŸ”Ž Scraping page 175 ...\n",
      "ðŸ”Ž Scraping page 176 ...\n",
      "ðŸ”Ž Scraping page 177 ...\n",
      "ðŸ”Ž Scraping page 178 ...\n",
      "ðŸ”Ž Scraping page 179 ...\n",
      "ðŸ”Ž Scraping page 180 ...\n",
      "ðŸ”Ž Scraping page 181 ...\n",
      "ðŸ”Ž Scraping page 182 ...\n",
      "ðŸ”Ž Scraping page 183 ...\n",
      "ðŸ”Ž Scraping page 184 ...\n",
      "ðŸ”Ž Scraping page 185 ...\n",
      "ðŸ”Ž Scraping page 186 ...\n",
      "ðŸ”Ž Scraping page 187 ...\n",
      "ðŸ”Ž Scraping page 188 ...\n",
      "ðŸ”Ž Scraping page 189 ...\n",
      "ðŸ”Ž Scraping page 190 ...\n",
      "ðŸ”Ž Scraping page 191 ...\n",
      "ðŸ”Ž Scraping page 192 ...\n",
      "ðŸ”Ž Scraping page 193 ...\n",
      "ðŸ”Ž Scraping page 194 ...\n",
      "ðŸ”Ž Scraping page 195 ...\n",
      "ðŸ”Ž Scraping page 196 ...\n",
      "ðŸ”Ž Scraping page 197 ...\n",
      "ðŸ”Ž Scraping page 198 ...\n",
      "ðŸ”Ž Scraping page 199 ...\n",
      "ðŸ”Ž Scraping page 200 ...\n",
      "ðŸ”Ž Scraping page 201 ...\n",
      "ðŸ”Ž Scraping page 202 ...\n",
      "ðŸ”Ž Scraping page 203 ...\n",
      "ðŸ”Ž Scraping page 204 ...\n",
      "ðŸ”Ž Scraping page 205 ...\n",
      "ðŸ”Ž Scraping page 206 ...\n",
      "ðŸ”Ž Scraping page 207 ...\n",
      "ðŸ”Ž Scraping page 208 ...\n",
      "ðŸ”Ž Scraping page 209 ...\n",
      "ðŸ”Ž Scraping page 210 ...\n",
      "ðŸ”Ž Scraping page 211 ...\n",
      "ðŸ”Ž Scraping page 212 ...\n",
      "ðŸ”Ž Scraping page 213 ...\n",
      "ðŸ”Ž Scraping page 214 ...\n",
      "ðŸ”Ž Scraping page 215 ...\n",
      "ðŸ”Ž Scraping page 216 ...\n",
      "ðŸ”Ž Scraping page 217 ...\n",
      "ðŸ”Ž Scraping page 218 ...\n",
      "ðŸ”Ž Scraping page 219 ...\n",
      "ðŸ”Ž Scraping page 220 ...\n",
      "ðŸ”Ž Scraping page 221 ...\n",
      "ðŸ”Ž Scraping page 222 ...\n",
      "ðŸ”Ž Scraping page 223 ...\n",
      "ðŸ”Ž Scraping page 224 ...\n",
      "ðŸ”Ž Scraping page 225 ...\n",
      "ðŸ”Ž Scraping page 226 ...\n",
      "ðŸ”Ž Scraping page 227 ...\n",
      "ðŸ”Ž Scraping page 228 ...\n",
      "ðŸ”Ž Scraping page 229 ...\n",
      "ðŸ”Ž Scraping page 230 ...\n",
      "ðŸ”Ž Scraping page 231 ...\n",
      "ðŸ”Ž Scraping page 232 ...\n",
      "ðŸ”Ž Scraping page 233 ...\n",
      "ðŸ”Ž Scraping page 234 ...\n",
      "ðŸ”Ž Scraping page 235 ...\n",
      "ðŸ”Ž Scraping page 236 ...\n",
      "ðŸ”Ž Scraping page 237 ...\n",
      "ðŸ”Ž Scraping page 238 ...\n",
      "ðŸ”Ž Scraping page 239 ...\n",
      "ðŸ”Ž Scraping page 240 ...\n",
      "ðŸ”Ž Scraping page 241 ...\n",
      "ðŸ”Ž Scraping page 242 ...\n",
      "ðŸ”Ž Scraping page 243 ...\n",
      "ðŸ”Ž Scraping page 244 ...\n",
      "ðŸ”Ž Scraping page 245 ...\n",
      "ðŸ”Ž Scraping page 246 ...\n",
      "ðŸ”Ž Scraping page 247 ...\n",
      "ðŸ”Ž Scraping page 248 ...\n",
      "ðŸ”Ž Scraping page 249 ...\n",
      "ðŸ”Ž Scraping page 250 ...\n",
      "ðŸ”Ž Scraping page 251 ...\n",
      "ðŸ”Ž Scraping page 252 ...\n",
      "ðŸ”Ž Scraping page 253 ...\n",
      "ðŸ”Ž Scraping page 254 ...\n",
      "ðŸ”Ž Scraping page 255 ...\n",
      "ðŸ”Ž Scraping page 256 ...\n",
      "ðŸ”Ž Scraping page 257 ...\n",
      "ðŸ”Ž Scraping page 258 ...\n",
      "ðŸ”Ž Scraping page 259 ...\n",
      "ðŸ”Ž Scraping page 260 ...\n",
      "ðŸ”Ž Scraping page 261 ...\n",
      "ðŸ”Ž Scraping page 262 ...\n",
      "ðŸ”Ž Scraping page 263 ...\n",
      "ðŸ”Ž Scraping page 264 ...\n",
      "ðŸ”Ž Scraping page 265 ...\n",
      "ðŸ”Ž Scraping page 266 ...\n",
      "ðŸ”Ž Scraping page 267 ...\n",
      "ðŸ”Ž Scraping page 268 ...\n",
      "ðŸ”Ž Scraping page 269 ...\n",
      "ðŸ”Ž Scraping page 270 ...\n",
      "ðŸ”Ž Scraping page 271 ...\n",
      "ðŸ”Ž Scraping page 272 ...\n",
      "ðŸ”Ž Scraping page 273 ...\n",
      "ðŸ”Ž Scraping page 274 ...\n",
      "ðŸ”Ž Scraping page 275 ...\n",
      "ðŸ”Ž Scraping page 276 ...\n",
      "ðŸ”Ž Scraping page 277 ...\n",
      "ðŸ”Ž Scraping page 278 ...\n",
      "ðŸ”Ž Scraping page 279 ...\n",
      "ðŸ”Ž Scraping page 280 ...\n",
      "ðŸ”Ž Scraping page 281 ...\n",
      "ðŸ”Ž Scraping page 282 ...\n",
      "ðŸ”Ž Scraping page 283 ...\n",
      "ðŸ”Ž Scraping page 284 ...\n",
      "ðŸ”Ž Scraping page 285 ...\n",
      "ðŸ”Ž Scraping page 286 ...\n",
      "ðŸ”Ž Scraping page 287 ...\n",
      "ðŸ”Ž Scraping page 288 ...\n",
      "ðŸ”Ž Scraping page 289 ...\n",
      "ðŸ”Ž Scraping page 290 ...\n",
      "ðŸ”Ž Scraping page 291 ...\n",
      "ðŸ”Ž Scraping page 292 ...\n",
      "ðŸ”Ž Scraping page 293 ...\n",
      "ðŸ”Ž Scraping page 294 ...\n",
      "ðŸ”Ž Scraping page 295 ...\n",
      "ðŸ”Ž Scraping page 296 ...\n",
      "ðŸ”Ž Scraping page 297 ...\n",
      "ðŸ”Ž Scraping page 298 ...\n",
      "ðŸ”Ž Scraping page 299 ...\n",
      "ðŸ”Ž Scraping page 300 ...\n",
      "ðŸ”Ž Scraping page 301 ...\n",
      "ðŸ”Ž Scraping page 302 ...\n",
      "ðŸ”Ž Scraping page 303 ...\n",
      "ðŸ”Ž Scraping page 304 ...\n",
      "ðŸ”Ž Scraping page 305 ...\n",
      "ðŸ”Ž Scraping page 306 ...\n",
      "ðŸ”Ž Scraping page 307 ...\n",
      "ðŸ”Ž Scraping page 308 ...\n",
      "ðŸ”Ž Scraping page 309 ...\n",
      "ðŸ”Ž Scraping page 310 ...\n",
      "ðŸ”Ž Scraping page 311 ...\n",
      "ðŸ”Ž Scraping page 312 ...\n",
      "ðŸ”Ž Scraping page 313 ...\n",
      "ðŸ”Ž Scraping page 314 ...\n",
      "ðŸ”Ž Scraping page 315 ...\n",
      "ðŸ”Ž Scraping page 316 ...\n",
      "ðŸ”Ž Scraping page 317 ...\n",
      "ðŸ”Ž Scraping page 318 ...\n",
      "ðŸ”Ž Scraping page 319 ...\n",
      "ðŸ”Ž Scraping page 320 ...\n",
      "ðŸ”Ž Scraping page 321 ...\n",
      "ðŸ”Ž Scraping page 322 ...\n",
      "ðŸ”Ž Scraping page 323 ...\n",
      "ðŸ”Ž Scraping page 324 ...\n",
      "ðŸ”Ž Scraping page 325 ...\n",
      "ðŸ”Ž Scraping page 326 ...\n",
      "ðŸ”Ž Scraping page 327 ...\n",
      "ðŸ”Ž Scraping page 328 ...\n",
      "ðŸ”Ž Scraping page 329 ...\n",
      "ðŸ”Ž Scraping page 330 ...\n",
      "ðŸ”Ž Scraping page 331 ...\n",
      "ðŸ”Ž Scraping page 332 ...\n",
      "ðŸ”Ž Scraping page 333 ...\n",
      "ðŸ”Ž Scraping page 334 ...\n",
      "ðŸ”Ž Scraping page 335 ...\n",
      "ðŸ”Ž Scraping page 336 ...\n",
      "ðŸ”Ž Scraping page 337 ...\n",
      "ðŸ”Ž Scraping page 338 ...\n",
      "ðŸ”Ž Scraping page 339 ...\n",
      "ðŸ”Ž Scraping page 340 ...\n",
      "ðŸ”Ž Scraping page 341 ...\n",
      "ðŸ”Ž Scraping page 342 ...\n",
      "ðŸ”Ž Scraping page 343 ...\n",
      "ðŸ”Ž Scraping page 344 ...\n",
      "ðŸ”Ž Scraping page 345 ...\n",
      "ðŸ”Ž Scraping page 346 ...\n",
      "ðŸ”Ž Scraping page 347 ...\n",
      "ðŸ”Ž Scraping page 348 ...\n",
      "ðŸ”Ž Scraping page 349 ...\n",
      "ðŸ”Ž Scraping page 350 ...\n",
      "ðŸ”Ž Scraping page 351 ...\n",
      "ðŸ”Ž Scraping page 352 ...\n",
      "ðŸ”Ž Scraping page 353 ...\n",
      "ðŸ”Ž Scraping page 354 ...\n",
      "ðŸ”Ž Scraping page 355 ...\n",
      "ðŸ”Ž Scraping page 356 ...\n",
      "ðŸ”Ž Scraping page 357 ...\n",
      "ðŸ”Ž Scraping page 358 ...\n",
      "ðŸ”Ž Scraping page 359 ...\n",
      "ðŸ”Ž Scraping page 360 ...\n",
      "ðŸ”Ž Scraping page 361 ...\n",
      "ðŸ”Ž Scraping page 362 ...\n",
      "ðŸ”Ž Scraping page 363 ...\n",
      "ðŸ”Ž Scraping page 364 ...\n",
      "ðŸ”Ž Scraping page 365 ...\n",
      "ðŸ”Ž Scraping page 366 ...\n",
      "ðŸ”Ž Scraping page 367 ...\n",
      "ðŸ”Ž Scraping page 368 ...\n",
      "ðŸ”Ž Scraping page 369 ...\n",
      "ðŸ”Ž Scraping page 370 ...\n",
      "ðŸ”Ž Scraping page 371 ...\n",
      "ðŸ”Ž Scraping page 372 ...\n",
      "ðŸ”Ž Scraping page 373 ...\n",
      "ðŸ”Ž Scraping page 374 ...\n",
      "ðŸ”Ž Scraping page 375 ...\n",
      "ðŸ”Ž Scraping page 376 ...\n",
      "ðŸ”Ž Scraping page 377 ...\n",
      "ðŸ”Ž Scraping page 378 ...\n",
      "ðŸ”Ž Scraping page 379 ...\n",
      "ðŸ”Ž Scraping page 380 ...\n",
      "ðŸ”Ž Scraping page 381 ...\n",
      "ðŸ”Ž Scraping page 382 ...\n",
      "ðŸ”Ž Scraping page 383 ...\n",
      "ðŸ”Ž Scraping page 384 ...\n",
      "ðŸ”Ž Scraping page 385 ...\n",
      "ðŸ”Ž Scraping page 386 ...\n",
      "ðŸ”Ž Scraping page 387 ...\n",
      "ðŸ”Ž Scraping page 388 ...\n",
      "ðŸ”Ž Scraping page 389 ...\n",
      "ðŸ”Ž Scraping page 390 ...\n",
      "ðŸ”Ž Scraping page 391 ...\n",
      "ðŸ”Ž Scraping page 392 ...\n",
      "ðŸ”Ž Scraping page 393 ...\n",
      "ðŸ”Ž Scraping page 394 ...\n",
      "ðŸ”Ž Scraping page 395 ...\n",
      "ðŸ”Ž Scraping page 396 ...\n",
      "ðŸ”Ž Scraping page 397 ...\n",
      "ðŸ”Ž Scraping page 398 ...\n",
      "ðŸ”Ž Scraping page 399 ...\n",
      "ðŸ”Ž Scraping page 400 ...\n",
      "ðŸ”Ž Scraping page 401 ...\n",
      "ðŸ”Ž Scraping page 402 ...\n",
      "ðŸ”Ž Scraping page 403 ...\n",
      "ðŸ”Ž Scraping page 404 ...\n",
      "ðŸ”Ž Scraping page 405 ...\n",
      "ðŸ”Ž Scraping page 406 ...\n",
      "ðŸ”Ž Scraping page 407 ...\n",
      "ðŸ”Ž Scraping page 408 ...\n",
      "ðŸ”Ž Scraping page 409 ...\n",
      "ðŸ”Ž Scraping page 410 ...\n",
      "ðŸ”Ž Scraping page 411 ...\n",
      "ðŸ”Ž Scraping page 412 ...\n",
      "ðŸ”Ž Scraping page 413 ...\n",
      "ðŸ”Ž Scraping page 414 ...\n",
      "ðŸ”Ž Scraping page 415 ...\n",
      "ðŸ”Ž Scraping page 416 ...\n",
      "ðŸ”Ž Scraping page 417 ...\n",
      "ðŸ”Ž Scraping page 418 ...\n",
      "ðŸ”Ž Scraping page 419 ...\n",
      "ðŸ”Ž Scraping page 420 ...\n",
      "ðŸ”Ž Scraping page 421 ...\n",
      "ðŸ”Ž Scraping page 422 ...\n",
      "ðŸ”Ž Scraping page 423 ...\n",
      "ðŸ”Ž Scraping page 424 ...\n",
      "ðŸ”Ž Scraping page 425 ...\n",
      "ðŸ”Ž Scraping page 426 ...\n",
      "ðŸ”Ž Scraping page 427 ...\n",
      "ðŸ”Ž Scraping page 428 ...\n",
      "ðŸ”Ž Scraping page 429 ...\n",
      "ðŸ”Ž Scraping page 430 ...\n",
      "ðŸ”Ž Scraping page 431 ...\n",
      "ðŸ”Ž Scraping page 432 ...\n",
      "ðŸ”Ž Scraping page 433 ...\n",
      "ðŸ”Ž Scraping page 434 ...\n",
      "ðŸ”Ž Scraping page 435 ...\n",
      "ðŸ”Ž Scraping page 436 ...\n",
      "ðŸ”Ž Scraping page 437 ...\n",
      "ðŸ”Ž Scraping page 438 ...\n",
      "ðŸ”Ž Scraping page 439 ...\n",
      "ðŸ”Ž Scraping page 440 ...\n",
      "ðŸ”Ž Scraping page 441 ...\n",
      "ðŸ”Ž Scraping page 442 ...\n",
      "ðŸ”Ž Scraping page 443 ...\n",
      "ðŸ”Ž Scraping page 444 ...\n",
      "ðŸ”Ž Scraping page 445 ...\n",
      "ðŸ”Ž Scraping page 446 ...\n",
      "ðŸ”Ž Scraping page 447 ...\n",
      "ðŸ”Ž Scraping page 448 ...\n",
      "ðŸ”Ž Scraping page 449 ...\n",
      "ðŸ”Ž Scraping page 450 ...\n",
      "ðŸ”Ž Scraping page 451 ...\n",
      "ðŸ”Ž Scraping page 452 ...\n",
      "ðŸ”Ž Scraping page 453 ...\n",
      "ðŸ”Ž Scraping page 454 ...\n",
      "ðŸ”Ž Scraping page 455 ...\n",
      "ðŸ”Ž Scraping page 456 ...\n",
      "ðŸ”Ž Scraping page 457 ...\n",
      "ðŸ”Ž Scraping page 458 ...\n",
      "ðŸ”Ž Scraping page 459 ...\n",
      "ðŸ”Ž Scraping page 460 ...\n",
      "ðŸ”Ž Scraping page 461 ...\n",
      "ðŸ”Ž Scraping page 462 ...\n",
      "ðŸ”Ž Scraping page 463 ...\n",
      "ðŸ”Ž Scraping page 464 ...\n",
      "ðŸ”Ž Scraping page 465 ...\n",
      "ðŸ”Ž Scraping page 466 ...\n",
      "ðŸ”Ž Scraping page 467 ...\n",
      "ðŸ”Ž Scraping page 468 ...\n",
      "ðŸ”Ž Scraping page 469 ...\n",
      "ðŸ”Ž Scraping page 470 ...\n",
      "ðŸ”Ž Scraping page 471 ...\n",
      "ðŸ”Ž Scraping page 472 ...\n",
      "ðŸ”Ž Scraping page 473 ...\n",
      "ðŸ”Ž Scraping page 474 ...\n",
      "ðŸ”Ž Scraping page 475 ...\n",
      "ðŸ”Ž Scraping page 476 ...\n",
      "ðŸ”Ž Scraping page 477 ...\n",
      "ðŸ”Ž Scraping page 478 ...\n",
      "ðŸ”Ž Scraping page 479 ...\n",
      "ðŸ”Ž Scraping page 480 ...\n",
      "ðŸ”Ž Scraping page 481 ...\n",
      "ðŸ”Ž Scraping page 482 ...\n",
      "ðŸ”Ž Scraping page 483 ...\n",
      "ðŸ”Ž Scraping page 484 ...\n",
      "ðŸ”Ž Scraping page 485 ...\n",
      "ðŸ”Ž Scraping page 486 ...\n",
      "ðŸ”Ž Scraping page 487 ...\n",
      "ðŸ”Ž Scraping page 488 ...\n",
      "ðŸ”Ž Scraping page 489 ...\n",
      "ðŸ”Ž Scraping page 490 ...\n",
      "ðŸ”Ž Scraping page 491 ...\n",
      "ðŸ”Ž Scraping page 492 ...\n",
      "ðŸ”Ž Scraping page 493 ...\n",
      "ðŸ”Ž Scraping page 494 ...\n",
      "ðŸ”Ž Scraping page 495 ...\n",
      "ðŸ”Ž Scraping page 496 ...\n",
      "ðŸ”Ž Scraping page 497 ...\n",
      "ðŸ”Ž Scraping page 498 ...\n",
      "ðŸ”Ž Scraping page 499 ...\n",
      "ðŸ”Ž Scraping page 500 ...\n",
      "ðŸ”Ž Scraping page 501 ...\n",
      "ðŸ”Ž Scraping page 502 ...\n",
      "ðŸ”Ž Scraping page 503 ...\n",
      "ðŸ”Ž Scraping page 504 ...\n",
      "ðŸ”Ž Scraping page 505 ...\n",
      "ðŸ”Ž Scraping page 506 ...\n",
      "ðŸ”Ž Scraping page 507 ...\n",
      "ðŸ”Ž Scraping page 508 ...\n",
      "ðŸ”Ž Scraping page 509 ...\n",
      "ðŸ”Ž Scraping page 510 ...\n",
      "ðŸ”Ž Scraping page 511 ...\n",
      "ðŸ”Ž Scraping page 512 ...\n",
      "ðŸ”Ž Scraping page 513 ...\n",
      "ðŸ”Ž Scraping page 514 ...\n",
      "ðŸ”Ž Scraping page 515 ...\n",
      "ðŸ”Ž Scraping page 516 ...\n",
      "ðŸ”Ž Scraping page 517 ...\n",
      "ðŸ”Ž Scraping page 518 ...\n",
      "ðŸ”Ž Scraping page 519 ...\n",
      "ðŸ”Ž Scraping page 520 ...\n",
      "ðŸ”Ž Scraping page 521 ...\n",
      "ðŸ”Ž Scraping page 522 ...\n",
      "ðŸ”Ž Scraping page 523 ...\n",
      "ðŸ”Ž Scraping page 524 ...\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:300\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    842\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    843\u001b[0m )\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\http\\client.py:300\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”Ž Scraping page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m url \u001b[38;5;241m=\u001b[39m BASE_URL \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(page)\n\u001b[1;32m---> 67\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Page failed to load. Stopping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Phython\\Lib\\site-packages\\requests\\adapters.py:604\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 1. IMPORT LIBRARIES\n",
    "# -----------------------------------------\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. HEADERS + BASE URL\n",
    "# -----------------------------------------\n",
    "BASE_URL = \"https://land.ng/search-results/?keyword=&states%5B%5D=lagos&page=\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/126.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. HELPER FUNCTIONS\n",
    "# -----------------------------------------\n",
    "\n",
    "def extract_price(price_text):\n",
    "    \"\"\"Convert â‚¦ values to numbers.\"\"\"\n",
    "    if not price_text:\n",
    "        return None\n",
    "\n",
    "    clean = re.sub(r\"[^\\d]\", \"\", price_text)\n",
    "    return int(clean) if clean.isdigit() else None\n",
    "\n",
    "\n",
    "def extract_land_size(text):\n",
    "    \"\"\"Extract land size number from text (sqm, plot, acres).\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    match = re.search(r\"(\\d+(\\.\\d+)?)\", text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_coordinates(text):\n",
    "    \"\"\"Find 2 coordinates inside a string.\"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "\n",
    "    coords = re.findall(r\"[-+]?\\d*\\.\\d+\", text)\n",
    "    if len(coords) >= 2:\n",
    "        return coords[0], coords[1]\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. SCRAPING LOOP (SCRAPES UNTIL NO MORE PAGES)\n",
    "# -----------------------------------------\n",
    "all_listings = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"ðŸ”Ž Scraping page {page} ...\")\n",
    "\n",
    "    url = BASE_URL + str(page)\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"âŒ Page failed to load. Stopping.\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    listings = soup.find_all(\"div\", class_=\"item-wrap\")\n",
    "\n",
    "    if not listings:\n",
    "        print(\"â›” No more listings. Finished scraping.\")\n",
    "        break\n",
    "\n",
    "    for item in listings:\n",
    "        # Title + Link\n",
    "        title_tag = item.find(\"h2\", class_=\"item-title\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else None\n",
    "        link = title_tag.find(\"a\")[\"href\"] if title_tag else None\n",
    "\n",
    "        # Price\n",
    "        price_tag = item.find(\"div\", class_=\"item-price\")\n",
    "        price_text = price_tag.get_text(strip=True) if price_tag else None\n",
    "        price_value = extract_price(price_text)\n",
    "\n",
    "        # Location\n",
    "        loc_tag = item.find(\"address\", class_=\"item-address\")\n",
    "        location = loc_tag.get_text(strip=True) if loc_tag else None\n",
    "\n",
    "        # Coordinates (if hidden in HTML)\n",
    "        lat, lon = extract_coordinates(str(item))\n",
    "\n",
    "        # Land attributes\n",
    "        land_info = item.find(\"ul\", class_=\"item-amenities\")\n",
    "        land_size, land_type = None, None\n",
    "\n",
    "        if land_info:\n",
    "            info_text = land_info.get_text(\" \", strip=True)\n",
    "            land_size = extract_land_size(info_text)\n",
    "            land_type = info_text\n",
    "\n",
    "        # Compute price per sqm\n",
    "        avg_sqm = None\n",
    "        if price_value and land_size:\n",
    "            avg_sqm = round(price_value / land_size, 2)\n",
    "\n",
    "        # Save record\n",
    "        all_listings.append({\n",
    "            \"Title\": title,\n",
    "            \"Link\": link,\n",
    "            \"Price (â‚¦)\": price_value,\n",
    "            \"Location\": location,\n",
    "            \"Land Size\": land_size,\n",
    "            \"Land Type\": land_type,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"Average â‚¦/sqm\": avg_sqm\n",
    "        })\n",
    "\n",
    "    page += 1\n",
    "    time.sleep(2)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. SAVE DATASET\n",
    "# -----------------------------------------\n",
    "df = pd.DataFrame(all_listings)\n",
    "\n",
    "save_path = r\"C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_lagos_properties.csv\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nâœ… DONE â€” Total listings collected: {len(df)}\")\n",
    "print(f\"ðŸ“ Saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b9156-deca-400e-a6b3-81439355a137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
