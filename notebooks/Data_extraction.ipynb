{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a846d1f9-db49-4a8d-9a79-91b14f64d6c8",
   "metadata": {},
   "source": [
    "# Data Extraction from land.ng website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ea75d7-7e18-4b8d-a394-e9d7d9af0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import necessary libaries \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02db668-3da5-47c0-85de-f6b5e1fbf64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load the website\n",
    "BASE_URL = \"https://land.ng/search-results/?keyword=&states%5B%5D=lagos&page=\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# clean numbers from price\n",
    "def clean_price(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    text = text.replace(\"₦\", \"\").replace(\",\", \"\")\n",
    "    numbers = re.findall(r\"\\d+\", text)\n",
    "    return int(numbers[0]) if numbers else None\n",
    "\n",
    "# clean sqm\n",
    "def clean_sqm(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    numbers = re.findall(r\"\\d+\", text)\n",
    "    return int(numbers[0]) if numbers else None\n",
    "\n",
    "# get coordinates from detail page\n",
    "def get_coordinates(detail_url):\n",
    "    try:\n",
    "        html = requests.get(detail_url, headers=HEADERS, timeout=15).text\n",
    "        coords = re.findall(r\"([-+]?\\d{1,2}\\.\\d+)\", html)\n",
    "        if len(coords) >= 2:\n",
    "            return coords[0], coords[1]\n",
    "    except:\n",
    "        return None, None\n",
    "    return None, None\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# scrape only 6 pages\n",
    "for page in range(1, 7):\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    url = BASE_URL + str(page)\n",
    "\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    listings = soup.find_all(\"div\", class_=\"item-wrap\")\n",
    "    if not listings:\n",
    "        print(\"No listings found. Stopping.\")\n",
    "        break\n",
    "\n",
    "    for item in listings:\n",
    "        # TITLE + LINK\n",
    "        title_tag = item.find(\"h2\", class_=\"item-title\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else None\n",
    "        link = title_tag.find(\"a\")[\"href\"] if title_tag else None\n",
    "\n",
    "        # PRICE\n",
    "        price_tag = item.find(\"li\", class_=\"item-price\")\n",
    "        price_raw = price_tag.get_text(strip=True) if price_tag else None\n",
    "        price_clean = clean_price(price_raw)\n",
    "\n",
    "        # LOCATION\n",
    "        loc_tag = item.find(\"address\", class_=\"item-address\")\n",
    "        location = loc_tag.get_text(strip=True) if loc_tag else None\n",
    "\n",
    "        #price type\n",
    "        price_type_tag = item.select_one(\"span.price-postfix\")\n",
    "        price_type = price_type_tag.text.strip() if price_type_tag else None\n",
    "\n",
    "\n",
    "        # LAND SIZE + TYPE\n",
    "        land_size = None\n",
    "        land_type = None\n",
    "\n",
    "        am = item.find(\"ul\", class_=\"item-amenities-with-icons\")\n",
    "        if am:\n",
    "            for li in am.find_all(\"li\"):\n",
    "                text = li.get_text(strip=True)\n",
    "                if \"Square\" in text:\n",
    "                    land_size = clean_sqm(text)\n",
    "                else:\n",
    "                    land_type = text  # last text is land type\n",
    "\n",
    "        # COORDINATES\n",
    "        lat, lon = get_coordinates(link) if link else (None, None)\n",
    "\n",
    "        # AVERAGE NAIRA PER SQM\n",
    "        if price_clean and land_size:\n",
    "            avg = round(price_clean / land_size, 2)\n",
    "        else:\n",
    "            avg = None\n",
    "\n",
    "        all_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Link\": link,\n",
    "            \"Price (₦)\": price_clean,\n",
    "            \"Location\": location,\n",
    "            \"Land Size (sqm)\": land_size,\n",
    "            \"Land Type\": land_type,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"price type\": price_type,\n",
    "            \"Average ₦/sqm\": avg\n",
    "        })\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "# SAVE TO CSV\n",
    "save_path = r\"C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_full_dataset.csv\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "pd.DataFrame(all_data).to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nDone! Saved to:\", save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf785f3-6401-489d-892b-5e4db48a3354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
