{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8dae76-9fe4-4a42-854b-002ae0bced48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://land.ng/search-results/?keyword=&states%5B%5D=lagos\"\n",
    "\n",
    "HEADER = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/126.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "def make_connection(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADER)\n",
    "        if response.status_code == 200:\n",
    "            soup_content = BeautifulSoup(response.content, 'html.parser')\n",
    "            return soup_content\n",
    "        else:\n",
    "            print(f\"Resources Not available! Status Code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An Error occurs. Message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92cfc3d-5108-4e51-8231-a175e441175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = make_connection(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292bdc5e-2ff4-4c4f-9d76-2a6b1b6927c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds ALL land listing cards on the page\n",
    "land_content_all = content.find_all(\"div\", class_=\"item-listing-wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941f18b7-22ef-4c82-9c0b-15087bebb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land_scrapped_successfully: 12 land retrieved\n"
     ]
    }
   ],
   "source": [
    "EXTRACT COORDINATES FROM EACH LISTING PAGE\n",
    "# ------------------------------------------------------------\n",
    "def extract_coordinates(detail_soup):\n",
    "    scripts = detail_soup.find_all(\"script\")\n",
    "    lat, lng = None, None\n",
    "\n",
    "    for s in scripts:\n",
    "        text = s.text\n",
    "\n",
    "        # Pattern 1: \"lat\": \"6.524379\"\n",
    "        m1 = re.search(r'\"lat\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "        m2 = re.search(r'\"lng\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "\n",
    "        # Pattern 2: latitude: \"6.524379\"\n",
    "        m3 = re.search(r'latitude:\\s*\"([^\"]+)\"', text)\n",
    "        m4 = re.search(r'longitude:\\s*\"([^\"]+)\"', text)\n",
    "\n",
    "        if m1 and m2:\n",
    "            lat, lng = m1.group(1), m2.group(1)\n",
    "            break\n",
    "        if m3 and m4:\n",
    "            lat, lng = m3.group(1), m4.group(1)\n",
    "            break\n",
    "\n",
    "    return lat, lng\n",
    "EXTRACT AVERAGE NAIRA PER SQM\n",
    "# ------------------------------------------------------------\n",
    "def extract_naira_per_sqm(detail_soup):\n",
    "    item = detail_soup.find(\"strong\", string=lambda x: x and \"sqm\" in x.lower())\n",
    "    if item:\n",
    "        span = item.find_next(\"span\")\n",
    "        if span:\n",
    "            return span.get_text(strip=True)\n",
    "    return None\n",
    "def scrape_page_land(land_content):\n",
    "    \"\"\"\n",
    "    scrape single land \n",
    "    return a dictionary\n",
    "    \"\"\"\n",
    "all_lands = []\n",
    "\n",
    "for land_content in land_content_all:\n",
    "\n",
    "    land_price = land_content.find(\"li\", class_=\"item-price\")\n",
    "    land_price = land_price.get_text(strip=True) if land_price else None\n",
    "\n",
    "    land_title = land_content.find(\"h2\", class_=\"item-title\")\n",
    "    land_title = land_title.get_text(strip=True) if land_title else None\n",
    "\n",
    "    land_link = land_content.find(\"h2\", class_=\"item-title\")\n",
    "    land_link = land_link.find(\"a\")[\"href\"] if land_link and land_link.find(\"a\") else None\n",
    "\n",
    "    land_address = land_content.find(\"address\", class_=\"item-address\")\n",
    "    land_address = land_address.get_text(strip=True) if land_address else None\n",
    "\n",
    "    land_type = land_content.find(\"li\", class_=\"h-type\")\n",
    "    land_type = land_type.get_text(strip=True) if land_type else None\n",
    "\n",
    "    land_area = land_content.find(\"li\", class_=\"h-area\")\n",
    "    land_area = land_area.get_text(strip=True) if land_area else None\n",
    "\n",
    "    land_author = land_content.find(\"div\", class_=\"item-author\")\n",
    "    land_author = land_author.get_text(strip=True) if land_author else None\n",
    "\n",
    "     # --------- VISIT EACH LISTING PAGE FOR COORDINATES ----------\n",
    "    lat, lng, sqm = None, None, None\n",
    "\n",
    "    if land_link:\n",
    "        detail_soup = make_connection(land_link)\n",
    "        if detail_soup:\n",
    "            lat, lng = extract_coordinates(detail_soup)\n",
    "            sqm = extract_naira_per_sqm(detail_soup)\n",
    "\n",
    "    single_land = {\n",
    "        \"title\": land_title,\n",
    "        \"price\": land_price,\n",
    "        \"link\": land_link,\n",
    "        \"address\": land_address,\n",
    "        \"type\": land_type,\n",
    "        \"area\": land_area,\n",
    "        \"author\": land_author,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lng,\n",
    "        \"avg_naira_sqm\": sqm\n",
    "    }\n",
    "\n",
    "    all_lands.append(single_land)\n",
    "\n",
    "print(f\"land_scrapped_successfully: {len(all_lands)} land retrieved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cc1c63-7b8c-4928-aeb6-657613fe65ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_full_data.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO CSV\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "save_path = r\"C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_full_data.csv\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "pd.DataFrame(all_lands).to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved to:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3838d750-4b29-4a30-ac2f-61fb854113e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_page_land(land_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15880c65-3081-4ecf-a0a4-79905b8521d2",
   "metadata": {},
   "source": [
    "**attributes**\n",
    "-**land price**: land_content = content.find(\"li\", class_=\"item-price\").get_text()\n",
    "-**Land title**: land content = content.find(\"h2\", class_=\"item-title\").get_text()\n",
    "-**land link**: land_content = content.find(\"h2\", class_=\"item-title\"). find(\"a\").get(\"href\")\n",
    "-**land address**: land_content = content.find(\"address\", class_=\"item-address\").get_text()\n",
    "-**land type**: land_content = content.find(\"li\", class_=\"h-type\").get_text()\n",
    "-**land area**:land_content = content.find(\"li\", class_=\"h-area\").get_text()\n",
    "-**land author**land_content = content.find(\"div\", class_=\"item-author\").get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72741c43-2eb3-4458-9159-c1b2a09848ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                link  property_id latitude  \\\n",
      "0  https://land.ng/land/fenced-land-with-governor...        25149     None   \n",
      "1  https://land.ng/land/plot-of-land-close-to-dan...        25216     None   \n",
      "2  https://land.ng/land/land-on-block-12-orange-i...        25152     None   \n",
      "3  https://land.ng/land/freedom-city-estate-ibeju...        25104     None   \n",
      "4  https://land.ng/land/a-developers-fit-land-for...        24888     None   \n",
      "\n",
      "  longitude avg_price_sqm  \n",
      "0      None          None  \n",
      "1      None          None  \n",
      "2      None          None  \n",
      "3      None          None  \n",
      "4      None          None  \n",
      "Saved to: C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_lagos_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "HEADER = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "BASE = \"https://land.ng\"\n",
    "\n",
    "def get_soup(url):\n",
    "    r = requests.get(url, headers=HEADER)\n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def get_property_api(property_id):\n",
    "    api_url = f\"{BASE}/wp-json/houzez/v1/property/{property_id}\"\n",
    "    r = requests.get(api_url, headers=HEADER)\n",
    "    if r.status_code == 200:\n",
    "        return r.json()\n",
    "    return None\n",
    "\n",
    "def scrape_listing_card(card):\n",
    "    # Basic listing info\n",
    "    link_tag = card.find(\"h2\", class_=\"item-title\").find(\"a\")\n",
    "    link = link_tag[\"href\"]\n",
    "    full_link = link if link.startswith(\"http\") else BASE + link\n",
    "\n",
    "    # Go to detail page\n",
    "    soup = get_soup(full_link)\n",
    "\n",
    "    # Extract property_id from data-map\n",
    "    map_div = soup.find(\"div\", id=\"houzez-single-listing-map-address\") \\\n",
    "              or soup.find(\"div\", id=\"houzez-single-listing-map\")\n",
    "    property_id = None\n",
    "    if map_div and map_div.has_attr(\"data-map\"):\n",
    "        try:\n",
    "            data = json.loads(map_div[\"data-map\"])\n",
    "            property_id = data.get(\"property_id\") or data.get(\"post_id\")\n",
    "        except:\n",
    "            property_id = None\n",
    "\n",
    "    lat = lng = None\n",
    "    avg_price_sqm = None\n",
    "\n",
    "    if property_id:\n",
    "        api_data = get_property_api(property_id)\n",
    "        if api_data:\n",
    "            lat = api_data.get(\"lat\")\n",
    "            lng = api_data.get(\"lng\")\n",
    "            # Some sites store per-sqm price under a different key; try common ones\n",
    "            avg_price_sqm = api_data.get(\"price_sqft\") or api_data.get(\"price_sqm\") or api_data.get(\"price_unit\")\n",
    "\n",
    "    return {\n",
    "        \"link\": full_link,\n",
    "        \"property_id\": property_id,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lng,\n",
    "        \"avg_price_sqm\": avg_price_sqm\n",
    "    }\n",
    "\n",
    "# Example: scrape first page\n",
    "search_url = BASE + \"/search-results/?keyword=&states%5B%5D=lagos\"\n",
    "soup = get_soup(search_url)\n",
    "cards = soup.find_all(\"div\", class_=\"item-listing-wrap\")\n",
    "\n",
    "data = []\n",
    "for c in cards:\n",
    "    rec = scrape_listing_card(c)\n",
    "    data.append(rec)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "# Save if needed\n",
    "save_path = r\"C:\\Users\\THIS-PC\\Documents\\LagosPropIQ\\Data\\raw\\landsng_lagos_coordinates.csv\"\n",
    "df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bfb27-8015-4fda-b392-d751bdf7a04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
